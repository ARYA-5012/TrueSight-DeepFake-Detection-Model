# ğŸ›¡ï¸ TrueSight: A Multimodal Deepfake Detection Framework

> Because fake faces, voices, and videos shouldn't rewrite reality.

![Methodology Flowchart](cha.png)

## ğŸ§  Overview
**TrueSight** is a unified deepfake detection framework that operates across **image**, **video**, and **audio** modalities. Designed to fight misinformation and protect digital integrity, it combines the strengths of **EfficientNet**, **Lite3D-ResNet**, and **ResNet-1D** fused via a **transformer-based cross-modal attention module**.

The model is hardened through **adversarial training**, optimized with **INT8 quantization**, and benchmarked on **FaceForensics++**, **DFDC**, and **WaveFake**.

---

## ğŸš€ Key Features

- ğŸ” **Multimodal Detection**: Handles image, video, and audio deepfakes
- ğŸ§± **Transformer-Based Fusion**: Cross-attention for modality synergy
- ğŸ›¡ï¸ **Adversarial Robustness**: PGD-based evasion hardening
- âš¡ **Edge Deployment Ready**: Runs under 100ms with INT8 quantization
- ğŸ“Š **State-of-the-Art Accuracy**: Beats unimodal baselines on cross-dataset benchmarks

---

## ğŸ“ Project Structure

TrueSight/
â”œâ”€â”€ datasets/
â”‚ â”œâ”€â”€ images/
â”‚ â”œâ”€â”€ videos/
â”‚ â””â”€â”€ audio/
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ efficientnet_b4.py
â”‚ â”œâ”€â”€ lite3d_resnet.py
â”‚ â”œâ”€â”€ resnet1d_audio.py
â”‚ â””â”€â”€ transformer_fuser.py
â”œâ”€â”€ utils/
â”‚ â””â”€â”€ preprocessing.py
â”œâ”€â”€ outputs/
â”‚ â””â”€â”€ logs, checkpoints, metrics.json
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ truesight_pipeline.ipynb
â””â”€â”€ main.py

yaml
Copy
Edit

---

## ğŸ“¦ Installation

```bash
git clone https://github.com/your-username/TrueSight.git
cd TrueSight
pip install -r requirements.txt
âš™ï¸ Dependencies
Python 3.9+

PyTorch 2.0.1

Librosa 0.10.1

Transformers 4.38

Foolbox 3.3.1

OpenCV, NumPy, Matplotlib

ğŸ§ª Datasets Used
Modality	Dataset	Type	Samples
Image	FaceForensics++	GAN, Diffusion	150,000
Video	DFDC, Celeb-DF	Swap, Texture	30,000
Audio	WaveFake, ASVspoof	TTS, VC	50,000

ğŸ—ï¸ How to Run
Set up data directories:

bash
Copy
Edit
/TrueSight/datasets/
    â”œâ”€â”€ images/
    â”œâ”€â”€ videos/
    â””â”€â”€ audio/
Train the models

bash
Copy
Edit
python train.py --modality image
python train.py --modality video
python train.py --modality audio
Fuse and evaluate

bash
Copy
Edit
python evaluate.py --fusion True
Adversarial evaluation

bash
Copy
Edit
python adversarial_test.py --attack pgd
ğŸ“ˆ Results Summary
Model	AUC	F1 Score	Inference Time
EfficientNet-B4	92.1%	91.3%	42ms
Lite3D-ResNet	94.8%	93.6%	65ms
ResNet1D (Audio)	88.7%	87.9%	39ms
TrueSight (Fusion)	97.2%	96.3%	94ms

ğŸ¯ Use Cases
âœ… Social Media Fake Detection APIs

ğŸ—ï¸ Newsroom Verification Pipelines

ğŸ¥ Real-time Call & Stream Filtering

ğŸ” Robustness Add-Ons
PGD Adversarial Noise

Gaussian Blur & Compression (H.264, CRF=30)

Dialect Variation Testing (Planned VCTK integration)

ğŸ“Œ Future Work
ğŸ” Transfer learning from VCTK (110 accents)

ğŸ“± Knowledge distillation for <50MB mobile deployment

ğŸ§© GAN artifact hallucination under CRF > 40

ğŸ‘¨â€ğŸ’» Authors
Arya Yadav â€“ CSE (AI/ML), Bennett University

Mentored by: Jarvis â€“ AI Assistant, Iron-Clad Logic Mode âš™ï¸

ğŸ“œ License
MIT License Â© 2025 Arya Yadav
