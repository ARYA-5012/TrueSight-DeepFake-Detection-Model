# -*- coding: utf-8 -*-
"""Audio_DeepFake_Model_Evaluation

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/arya0513/audio-deepfake-model-evaluation.5e39eab7-80f9-4fff-91c0-7d749875e42b.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250626/auto/storage/goog4_request%26X-Goog-Date%3D20250626T175517Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D48663cb67b43011e6539ce919f5a1a21f64e2700f9d12bc27bec6f3cae26a5fdcad72ef6fe398f9eace319dddea1ff50c9a77e3d541fd6c8e6f2758526b124a650d0facdd2c8ee9be58794675804323de027a8299a94e17f2fe619b12b60266c3319a818e5e1cb846cddeaadbd92b4a740bfafc91ec26c8a939bbc8d574fbfe492b1968b29311626564d36a87bfda493587a81c62676c383d03a326230db551497507a9206fef144722103ce9e2f632ae03a5750c934b4979eef4ac892745b2f975c9f92137ab8de546f0251daa7b86ba57789c1b44904cbeabfd7f407c0fb3ce33ebfb87c82647f9258558972b0244cec37fb1c2ee806652ce1b01147225154
"""

import kagglehub
mathurinache_the_lj_speech_dataset_path = kagglehub.dataset_download('mathurinache/the-lj-speech-dataset')
andreadiubaldo_wavefake_test_path = kagglehub.dataset_download('andreadiubaldo/wavefake-test')
vivekshinde777_audio_deepfake_cnn_and_bilstm_model_tensorflow2_default_1_path = kagglehub.model_download('vivekshinde777/audio_deepfake_cnn-and-bilstm_model/TensorFlow2/default/1')

print('Data source import complete.')

import numpy as np
import pandas as pd
import os
import librosa
import matplotlib.pyplot as plt
import IPython
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation,Reshape,MaxPooling2D, Dropout, Conv2D, MaxPool2D, Flatten
from tensorflow.keras.utils import to_categorical

from google.colab import drive
import os

# 1. Mount Google Drive
drive.mount('/content/drive')

# 2. Define your custom directory paths
real_root_dir = '/content/drive/MyDrive/kaggle/input/the-lj-speech-dataset/LJSpeech-1.1/wavs'
fake_root_dir = '/content/drive/MyDrive/kaggle/input/wavefake-test/generated_audio/ljspeech_melgan'

# 3. Create these folders recursively
os.makedirs(real_root_dir, exist_ok=True)
os.makedirs(fake_root_dir, exist_ok=True)

print(" Folder structure created in your Google Drive.")

import os
from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

# Initialize lists
paths = []
labels = []

# Define the root directories in Google Drive
real_root_dir = '/content/drive/MyDrive/kaggle/input/the-lj-speech-dataset/LJSpeech-1.1/wavs'
fake_root_dir = '/content/drive/MyDrive/kaggle/input/wavefake-test/generated_audio/ljspeech_melgan'

# Iterate through the 'real' audio files
for filename in os.listdir(real_root_dir):
    file_path = os.path.join(real_root_dir, filename)
    paths.append(file_path)
    labels.append('real')

# Iterate through the 'fake' audio files
for filename in os.listdir(fake_root_dir):
    file_path = os.path.join(fake_root_dir, filename)
    paths.append(file_path)
    labels.append('fake')

print(f'Dataset is loaded. Total files: {len(paths)}')

df = pd.DataFrame()
df['speech'] = paths
df['label'] = labels

real_audio = '/kaggle/input/the-lj-speech-dataset/LJSpeech-1.1/wavs/LJ001-0001.wav'
fake_audio = '/kaggle/input/wavefake-test/generated_audio/ljspeech_melgan/LJ001-0001_gen.wav'

def extract_features(fake_root_dir, real_root_dir, max_length=500):
    features = []
    labels = []

    for file in os.listdir(fake_root_dir):
        file_path = os.path.join(fake_root_dir, file)
        try:
            # Load audio file
            audio, _ = librosa.load(file_path, sr=16000)
            # Extract features (example: using Mel-Frequency Cepstral Coefficients)
            mfccs = librosa.feature.mfcc(y=audio, sr=16000, n_mfcc=40)
            # Pad or trim the feature array to a fixed length
            if mfccs.shape[1] < max_length:
                mfccs = np.pad(mfccs, ((0, 0), (0, max_length - mfccs.shape[1])), mode='constant')
            else:
                mfccs = mfccs[:, :max_length]
            features.append(mfccs)
            # Assign label
            labels.append(1)  # 1 for fake

        except Exception as e:
            print(f"Error encountered while parsing file: {file_path}")
            continue

    for file in os.listdir(real_root_dir):
        file_path = os.path.join(real_root_dir, file)
        try:
            # Load audio file
            audio, _ = librosa.load(file_path, sr=16000)
            # Extract features (example: using Mel-Frequency Cepstral Coefficients)
            mfccs = librosa.feature.mfcc(y=audio, sr=16000, n_mfcc=40)
            # Pad or trim the feature array to a fixed length
            if mfccs.shape[1] < max_length:
                mfccs = np.pad(mfccs, ((0, 0), (0, max_length - mfccs.shape[1])), mode='constant')
            else:
                mfccs = mfccs[:, :max_length]
            features.append(mfccs)
            # Assign label
            labels.append(0)  # 0 for real
        except Exception as e:
            print(f"Error encountered while parsing file: {file_path}")
            continue
    return np.array(features), np.array(labels)

# Example usage

x, y = extract_features(fake_root_dir, real_root_dir)

print("Features shape:", x.shape)
print("Labels shape:", y.shape)

xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size = .2)

import os

directory = '/kaggle/input/audio_deepfake_cnn-and-bilstm_model/tensorflow2/default/'
for root, dirs, files in os.walk(directory):
    print(root)
    for file in files:
        print(f'File: {file}')

import tensorflow as tf
from tensorflow.keras import layers, Sequential, regularizers

def create_model(input_shape=(40, 500, 1)):
    model = Sequential([
        layers.InputLayer(input_shape=input_shape),
        layers.Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.MaxPooling2D(pool_size=(2, 2)),

        layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.MaxPooling2D(pool_size=(2, 2)),

        layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.MaxPooling2D(pool_size=(2, 2)),

        layers.Reshape((-1, 128)),
        layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.2)),
        layers.BatchNormalization(),
        layers.Bidirectional(layers.LSTM(128, dropout=0.3, recurrent_dropout=0.2)),
        layers.BatchNormalization(),
        layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),
        layers.Dropout(0.5),
        layers.Dense(1, activation='sigmoid')
    ])

    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

import tensorflow as tf
model = create_model()
model_path = '/kaggle/input/audio_deepfake_cnn-and-bilstm_model/tensorflow2/default/1/updated_model.h5'
model.load_weights(model_path)



from sklearn.metrics import precision_score, recall_score, confusion_matrix, accuracy_score


# Assuming your model is already trained
# X_test, y_test are your test data and true labels
y_pred = model.predict(xtest)
y_pred = (y_pred > 0.5).astype(int)  # Threshold the output to get binary class (0 or 1)

# Calculate precision and recall using sklearn
precision = precision_score(ytest, y_pred)
recall = recall_score(ytest, y_pred)
accuracy = accuracy_score(ytest, y_pred)

# Print the precision and recall values
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")

# Confusion Matrix
cm = confusion_matrix(ytest, y_pred)
print("Confusion Matrix:")
print(cm)

# You can also plot the confusion matrix
import seaborn as sns
import matplotlib.pyplot as plt

sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])
plt.ylabel('True labels')
plt.xlabel('Predicted labels')
plt.title('Confusion Matrix')
plt.show()







