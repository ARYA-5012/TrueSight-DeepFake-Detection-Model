# -*- coding: utf-8 -*-
"""Logistic1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sYx5pDXlNUEIwM-WzomwlwV-BFhyA9SR
"""

# Step 1: Install Kaggle
!pip install kaggle

# Step 2: Upload Kaggle API Key (kaggle.json)
from google.colab import files
files.upload()  # Choose the kaggle.json file from your local system

# Step 3: Move kaggle.json to the correct location
!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Step 4: Download the Dataset
!kaggle datasets download -d manjilkarki/deepfake-and-real-images

# Step 5: Unzip the Dataset
import zipfile
import os

# Create a directory for the dataset
dataset_dir = "deepfake_dataset"
os.makedirs(dataset_dir, exist_ok=True)

# Unzip the downloaded file
with zipfile.ZipFile("deepfake-and-real-images.zip", "r") as zip_ref:
    zip_ref.extractall(dataset_dir)

print(f"Dataset extracted to: {dataset_dir}")

import torch
import torch.nn as nn

class LogisticRegressionModel(nn.Module):
    def __init__(self, input_size, output_size):
        super(LogisticRegressionModel, self).__init__()
        self.fc = nn.Linear(input_size, output_size)  # Linear layer for logistic regression

    def forward(self, x):
        x = x.view(x.size(0), -1)  # Flatten the image into a vector
        x = self.fc(x)  # Apply linear transformation
        return x

import os
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# Define paths
dataset_dir = "/content/deepfake_dataset/Dataset"
train_dir = os.path.join(dataset_dir, "Train")
val_dir = os.path.join(dataset_dir, "Validation")
test_dir = os.path.join(dataset_dir, "Test")

# Define image transformations (resize and convert to tensor)
transform = transforms.Compose([
    transforms.Resize((128, 128)),  # Resize to 128x128 for faster computation
    transforms.ToTensor(),          # Convert images to PyTorch tensors
])

# Load datasets
train_data = datasets.ImageFolder(root=train_dir, transform=transform)
val_data = datasets.ImageFolder(root=val_dir, transform=transform)
test_data = datasets.ImageFolder(root=test_dir, transform=transform)

# Create data loaders
train_loader = DataLoader(train_data, batch_size=32, shuffle=True)
val_loader = DataLoader(val_data, batch_size=32, shuffle=False)
test_loader = DataLoader(test_data, batch_size=32, shuffle=False)

# Define the input and output size
input_size = 128 * 128 * 3  # Resized to 128x128 images with 3 channels
output_size = 2  # Two classes: "real" and "fake"

# Instantiate the model
model = LogisticRegressionModel(input_size, output_size)

# Print the model architecture
print(model)

# Define loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

from sklearn.metrics import accuracy_score

def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=5):
    for epoch in range(epochs):
        model.train()  # Set model to training mode
        running_loss = 0.0
        correct = 0
        total = 0

        # Training loop
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)  # Move to GPU if available

            optimizer.zero_grad()  # Zero the parameter gradients
            outputs = model(inputs)  # Forward pass
            loss = criterion(outputs, labels)  # Calculate loss
            loss.backward()  # Backward pass
            optimizer.step()  # Optimize the model parameters

            running_loss += loss.item()  # Track loss
            _, predicted = torch.max(outputs, 1)  # Get the predicted class
            total += labels.size(0)  # Count total samples
            correct += (predicted == labels).sum().item()  # Count correct predictions

        # Calculate accuracy for this epoch
        accuracy = (correct / total) * 100
        print(f"Epoch {epoch+1}/{epochs} - Loss: {running_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%")

        # Validation after each epoch
        evaluate_model(model, val_loader)

def evaluate_model(model, val_loader):
    model.eval()  # Set model to evaluation mode
    all_preds = []
    all_labels = []
    with torch.no_grad():  # Disable gradient calculation for evaluation
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs, 1)
            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    # Calculate validation accuracy
    accuracy = accuracy_score(all_labels, all_preds)
    print(f"Validation Accuracy: {accuracy * 100:.2f}%")

# Set device (GPU if available, else CPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Move model to the device (GPU/CPU)
model = model.to(device)

# Train the model
train_model(model, train_loader, val_loader, criterion, optimizer, epochs=5)

def test_model(model, test_loader):
    model.eval()  # Set model to evaluation mode
    all_preds = []
    all_labels = []
    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs, 1)
            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    accuracy = accuracy_score(all_labels, all_preds)
    print(f"Test Accuracy: {accuracy * 100:.2f}%")

# Evaluate on test set
test_model(model, test_loader)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

def plot_confusion_matrix(y_true, y_pred, class_names):
    # Generate the confusion matrix
    cm = confusion_matrix(y_true, y_pred)

    # Plot the confusion matrix
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
    disp.plot(cmap=plt.cm.Blues)
    plt.title("Confusion Matrix")
    plt.show()

# Modify the test_model function to include confusion matrix plotting
def test_model_with_confusion_matrix(model, test_loader, class_names):
    model.eval()  # Set model to evaluation mode
    all_preds = []
    all_labels = []
    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs, 1)
            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    # Calculate accuracy
    accuracy = accuracy_score(all_labels, all_preds)
    print(f"Test Accuracy: {accuracy * 100:.2f}%")

    # Plot confusion matrix
    plot_confusion_matrix(all_labels, all_preds, class_names)

# Define class names
class_names = train_data.classes  # Automatically fetch class names from the dataset

# Evaluate the model and plot the confusion matrix
test_model_with_confusion_matrix(model, test_loader, class_names)